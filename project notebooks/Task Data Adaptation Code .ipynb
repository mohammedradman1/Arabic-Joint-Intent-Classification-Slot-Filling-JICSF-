{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the data individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial After Limits Raising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# create an openAI connection\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-9aLij28eopt5P9vRXaM9LW', bytes=58107791, created_at=1737070835, filename='data.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "# upload the batch file to the server\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(\"./data.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(batch_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_67899950d9ac8190861d53e801b2d552', completion_window='24h', created_at=1737070928, endpoint='/v1/chat/completions', input_file_id='file-9aLij28eopt5P9vRXaM9LW', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1737157328, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'ner labelling'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "# create a batch work at the server\n",
    "batch_input_file_id = batch_input_file.id\n",
    "batch_info = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"ner labelling\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# print the batch information\n",
    "print(batch_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_67899950d9ac8190861d53e801b2d552', completion_window='24h', created_at=1737070928, endpoint='/v1/chat/completions', input_file_id='file-9aLij28eopt5P9vRXaM9LW', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1737073360, error_file_id=None, errors=None, expired_at=None, expires_at=1737157328, failed_at=None, finalizing_at=1737072613, in_progress_at=1737070931, metadata={'description': 'ner labelling'}, output_file_id='file-42QNSZqMV1z3Zi7NwDEq9h', request_counts=BatchRequestCounts(completed=7310, failed=0, total=7310))\n"
     ]
    }
   ],
   "source": [
    "# check on the status of the batch\n",
    "batch_status = client.batches.retrieve(batch_info.id)\n",
    "print(batch_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_id = \"file-42QNSZqMV1z3Zi7NwDEq9h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to retrieve the batch results \n",
    "file_response = client.files.content(\"file-42QNSZqMV1z3Zi7NwDEq9h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[Batch](data=[Batch(id='batch_67899950d9ac8190861d53e801b2d552', completion_window='24h', created_at=1737070928, endpoint='/v1/chat/completions', input_file_id='file-9aLij28eopt5P9vRXaM9LW', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1737073360, error_file_id=None, errors=None, expired_at=None, expires_at=1737157328, failed_at=None, finalizing_at=1737072613, in_progress_at=1737070931, metadata={'description': 'ner labelling'}, output_file_id='file-42QNSZqMV1z3Zi7NwDEq9h', request_counts=BatchRequestCounts(completed=7310, failed=0, total=7310)), Batch(id='batch_6789887331f88190941bb3234d57687e', completion_window='24h', created_at=1737066611, endpoint='/v1/chat/completions', input_file_id='file-Smkf2fgapcyuDJrQaos43Y', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-ZCADpKNwK8gZKyrrccuBt0Rt. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1737153011, failed_at=1737066612, finalizing_at=None, in_progress_at=None, metadata={'description': 'ner labelling'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_678987ded6b48190afdb06df586f5c61', completion_window='24h', created_at=1737066462, endpoint='/v1/chat/completions', input_file_id='file-E7HUdRVLSzeRjfySz47gva', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1737071653, error_file_id=None, errors=None, expired_at=None, expires_at=1737152862, failed_at=None, finalizing_at=1737071609, in_progress_at=1737066464, metadata={'description': 'ner labelling'}, output_file_id='file-Q7g93cfqC5Gi6StXvcmrvd', request_counts=BatchRequestCounts(completed=567, failed=0, total=567)), Batch(id='batch_6789875f23248190b8f14ca2a999c45e', completion_window='24h', created_at=1737066335, endpoint='/v1/chat/completions', input_file_id='file-2w4xForEphqZtVSyLz4b7Y', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-ZCADpKNwK8gZKyrrccuBt0Rt. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1737152735, failed_at=1737066336, finalizing_at=None, in_progress_at=None, metadata={'description': 'ner labelling'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_678984b36cec8190a5560442bd057eb1', completion_window='24h', created_at=1737065651, endpoint='/v1/chat/completions', input_file_id='file-Tg4y5tGyveLaD9fPqai34g', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-ZCADpKNwK8gZKyrrccuBt0Rt. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1737152051, failed_at=1737065653, finalizing_at=None, in_progress_at=None, metadata={'description': 'ner labelling'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_678981612e048190b5807c2100f4cdd0', completion_window='24h', created_at=1737064801, endpoint='/v1/chat/completions', input_file_id='file-SszESFunWW8uSNxR62nmyC', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-ZCADpKNwK8gZKyrrccuBt0Rt. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1737151201, failed_at=1737064802, finalizing_at=None, in_progress_at=None, metadata={'description': 'ner labelling'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_6789813afd9c81909fe1c81a3b0950a4', completion_window='24h', created_at=1737064763, endpoint='/v1/chat/completions', input_file_id='file-A6TmbMW5x4z7R65qLsy9tu', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-ZCADpKNwK8gZKyrrccuBt0Rt. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1737151163, failed_at=1737064764, finalizing_at=None, in_progress_at=None, metadata={'description': 'ner labelling'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_67898104d16881908a11cefde0e47099', completion_window='24h', created_at=1737064708, endpoint='/v1/chat/completions', input_file_id='file-41His7GH7HQuJWiBr7qcny', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-ZCADpKNwK8gZKyrrccuBt0Rt. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1737151108, failed_at=1737064709, finalizing_at=None, in_progress_at=None, metadata={'description': 'ner labelling'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_678980cfe5108190a2e2c4adaf5edb79', completion_window='24h', created_at=1737064656, endpoint='/v1/chat/completions', input_file_id='file-Nyk3heHMJwEd1r13T8owtS', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-ZCADpKNwK8gZKyrrccuBt0Rt. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1737151056, failed_at=1737064657, finalizing_at=None, in_progress_at=None, metadata={'description': 'ner labelling'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_6789809bc6cc8190b3fb323413dc426b', completion_window='24h', created_at=1737064603, endpoint='/v1/chat/completions', input_file_id='file-LhGtUhEu5axq9THJxUdA34', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o-mini in organization org-ZCADpKNwK8gZKyrrccuBt0Rt. Limit: 2,000,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list'), expired_at=None, expires_at=1737151003, failed_at=1737064604, finalizing_at=None, in_progress_at=None, metadata={'description': 'ner labelling'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))], object='list', first_id='batch_67899950d9ac8190861d53e801b2d552', last_id='batch_6789809bc6cc8190b3fb323413dc426b', has_more=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a list of all the batches\n",
    "client.batches.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"batch_output.jsonl\", \"w\") as f:\n",
    "    f.write(file_response.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "import jsonlines\n",
    "\n",
    "data = []\n",
    "with jsonlines.open('batch_output.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        data.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'batch_req_67899fe58c8c8190a0955ad225195809',\n",
       " 'custom_id': 'request-0',\n",
       " 'response': {'status_code': 200,\n",
       "  'request_id': '99ab28938ec092d4cddac493514ec1bc',\n",
       "  'body': {'id': 'chatcmpl-AqTn6aza0A2i0z2O4DhTlzVgCvthV',\n",
       "   'object': 'chat.completion',\n",
       "   'created': 1737070936,\n",
       "   'model': 'gpt-4o-mini-2024-07-18',\n",
       "   'choices': [{'index': 0,\n",
       "     'message': {'role': 'assistant',\n",
       "      'content': '```json\\n{\\n  \"entities\": [\\n    {\\n      \"text\": \"د. محمود السمرة\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 224,\\n      \"end_position\": 241\\n    },\\n    {\\n      \"text\": \"د. أمل نصير\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 292,\\n      \"end_position\": 304\\n    },\\n    {\\n      \"text\": \"طه حسين\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 363,\\n      \"end_position\": 371\\n    },\\n    {\\n      \"text\": \"الأربعاء\",\\n      \"category\": \"ORDINAL\",\\n      \"start_position\": 373,\\n      \"end_position\": 380\\n    },\\n    {\\n      \"text\": \"صحيفة الغد\",\\n      \"category\": \"ORG\",\\n      \"start_position\": 524,\\n      \"end_position\": 537\\n    },\\n    {\\n      \"text\": \"العالم\",\\n      \"category\": \"LOC\",\\n      \"start_position\": 22,\\n      \"end_position\": 27\\n    },\\n    {\\n      \"text\": \"العقاد\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 812,\\n      \"end_position\": 818\\n    },\\n    {\\n      \"text\": \"الكافوريات\",\\n      \"category\": \"CARDINAL\",\\n      \"start_position\": 815,\\n      \"end_position\": 828\\n    },\\n    {\\n      \"text\": \"الزمن\",\\n      \"category\": \"CARDINAL\",\\n      \"start_position\": 996,\\n      \"end_position\": 1001\\n    }\\n  ]\\n}\\n```',\n",
       "      'refusal': None},\n",
       "     'logprobs': None,\n",
       "     'finish_reason': 'stop'}],\n",
       "   'usage': {'prompt_tokens': 1546,\n",
       "    'completion_tokens': 346,\n",
       "    'total_tokens': 1892,\n",
       "    'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
       "    'completion_tokens_details': {'reasoning_tokens': 0,\n",
       "     'audio_tokens': 0,\n",
       "     'accepted_prediction_tokens': 0,\n",
       "     'rejected_prediction_tokens': 0}},\n",
       "   'service_tier': 'default',\n",
       "   'system_fingerprint': 'fp_bd83329f63'}},\n",
       " 'error': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = []\n",
    "\n",
    "for entry in data:\n",
    "    try:\n",
    "        choices = entry.get('response', {}).get('body', {}).get('choices', [])\n",
    "        if choices:\n",
    "            message_content = choices[0].get('message', {}).get('content', '')\n",
    "        else:\n",
    "            message_content = ''\n",
    "        \n",
    "        extracted_entry = {\n",
    "            'custom_id': entry.get('custom_id', ''),\n",
    "            'content': message_content\n",
    "        }\n",
    "        extracted_data.append(extracted_entry)\n",
    "    except KeyError as e:\n",
    "        print(f\"Key error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request-0</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request-1</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>request-2</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request-3</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request-4</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>request-7305</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7306</th>\n",
       "      <td>request-7306</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7307</th>\n",
       "      <td>request-7307</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7308</th>\n",
       "      <td>request-7308</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7309</th>\n",
       "      <td>request-7309</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7310 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         custom_id                                           entities\n",
       "0        request-0  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
       "1        request-1  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
       "2        request-2  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
       "3        request-3  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
       "4        request-4  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
       "...            ...                                                ...\n",
       "7305  request-7305  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
       "7306  request-7306  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
       "7307  request-7307  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
       "7308  request-7308  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
       "7309  request-7309  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
       "\n",
       "[7310 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame(extracted_data)\n",
    "output_df.rename(columns={\"content\":\"entities\"}, inplace = True)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading main data\n",
    "original_data = []\n",
    "with jsonlines.open('data.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        original_data.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = []\n",
    "\n",
    "for entry in original_data:\n",
    "    try:\n",
    "        text = entry.get(\"body\",{}).get(\"messages\", {})[1].get(\"content\", {}) \n",
    "        extracted_entry = {\n",
    "            'custom_id': entry.get('custom_id', ''),\n",
    "            'text': text\n",
    "        }\n",
    "        data_dic.append(extracted_entry)\n",
    "    except KeyError as e:\n",
    "        print(f\"Key error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request-0</td>\n",
       "      <td>يتناول المهرجان هذا العام العلاقة بين الشعر وا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request-1</td>\n",
       "      <td>لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>request-2</td>\n",
       "      <td>لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request-3</td>\n",
       "      <td>لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request-4</td>\n",
       "      <td>أصدر فاروق حسنى وزير الثقافة المصري قرارا بتعي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>request-7305</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - أقمار زحل عودة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7306</th>\n",
       "      <td>request-7306</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - أقمار زحل عودة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7307</th>\n",
       "      <td>request-7307</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - أقمار زحل عودة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7308</th>\n",
       "      <td>request-7308</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - حلقات زحل عودة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7309</th>\n",
       "      <td>request-7309</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - حلقات زحل عودة...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7310 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         custom_id                                               text\n",
       "0        request-0  يتناول المهرجان هذا العام العلاقة بين الشعر وا...\n",
       "1        request-1  لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...\n",
       "2        request-2  لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...\n",
       "3        request-3  لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...\n",
       "4        request-4  أصدر فاروق حسنى وزير الثقافة المصري قرارا بتعي...\n",
       "...            ...                                                ...\n",
       "7305  request-7305  موقع الكون - المجموعة الشمسية - أقمار زحل عودة...\n",
       "7306  request-7306  موقع الكون - المجموعة الشمسية - أقمار زحل عودة...\n",
       "7307  request-7307  موقع الكون - المجموعة الشمسية - أقمار زحل عودة...\n",
       "7308  request-7308  موقع الكون - المجموعة الشمسية - حلقات زحل عودة...\n",
       "7309  request-7309  موقع الكون - المجموعة الشمسية - حلقات زحل عودة...\n",
       "\n",
       "[7310 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(data_dic)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request-0</td>\n",
       "      <td>يتناول المهرجان هذا العام العلاقة بين الشعر وا...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request-1</td>\n",
       "      <td>لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>request-2</td>\n",
       "      <td>لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request-3</td>\n",
       "      <td>لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request-4</td>\n",
       "      <td>أصدر فاروق حسنى وزير الثقافة المصري قرارا بتعي...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>request-7305</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - أقمار زحل عودة...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7306</th>\n",
       "      <td>request-7306</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - أقمار زحل عودة...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7307</th>\n",
       "      <td>request-7307</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - أقمار زحل عودة...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7308</th>\n",
       "      <td>request-7308</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - حلقات زحل عودة...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7309</th>\n",
       "      <td>request-7309</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - حلقات زحل عودة...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7310 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         custom_id                                               text  \\\n",
       "0        request-0  يتناول المهرجان هذا العام العلاقة بين الشعر وا...   \n",
       "1        request-1  لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...   \n",
       "2        request-2  لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...   \n",
       "3        request-3  لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...   \n",
       "4        request-4  أصدر فاروق حسنى وزير الثقافة المصري قرارا بتعي...   \n",
       "...            ...                                                ...   \n",
       "7305  request-7305  موقع الكون - المجموعة الشمسية - أقمار زحل عودة...   \n",
       "7306  request-7306  موقع الكون - المجموعة الشمسية - أقمار زحل عودة...   \n",
       "7307  request-7307  موقع الكون - المجموعة الشمسية - أقمار زحل عودة...   \n",
       "7308  request-7308  موقع الكون - المجموعة الشمسية - حلقات زحل عودة...   \n",
       "7309  request-7309  موقع الكون - المجموعة الشمسية - حلقات زحل عودة...   \n",
       "\n",
       "                                               entities  \n",
       "0     ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  \n",
       "1     ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  \n",
       "2     ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  \n",
       "3     ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  \n",
       "4     ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  \n",
       "...                                                 ...  \n",
       "7305  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  \n",
       "7306  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  \n",
       "7307  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  \n",
       "7308  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  \n",
       "7309  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  \n",
       "\n",
       "[7310 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes on their custom-id\n",
    "df = pd.merge(data_df, output_df, on=\"custom_id\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "      <td>يتناول المهرجان هذا العام العلاقة بين الشعر وا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "      <td>لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "      <td>لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "      <td>لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "      <td>أصدر فاروق حسنى وزير الثقافة المصري قرارا بتعي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>فلك-علوم بحتة</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - أقمار زحل عودة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7306</th>\n",
       "      <td>فلك-علوم بحتة</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - أقمار زحل عودة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7307</th>\n",
       "      <td>فلك-علوم بحتة</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - أقمار زحل عودة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7308</th>\n",
       "      <td>فلك-علوم بحتة</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - حلقات زحل عودة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7309</th>\n",
       "      <td>فلك-علوم بحتة</td>\n",
       "      <td>موقع الكون - المجموعة الشمسية - حلقات زحل عودة...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7310 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title                                               text\n",
       "0     الأدب العربي-أدبيات  يتناول المهرجان هذا العام العلاقة بين الشعر وا...\n",
       "1     الأدب العربي-أدبيات  لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...\n",
       "2     الأدب العربي-أدبيات  لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...\n",
       "3     الأدب العربي-أدبيات  لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة ...\n",
       "4     الأدب العربي-أدبيات  أصدر فاروق حسنى وزير الثقافة المصري قرارا بتعي...\n",
       "...                     ...                                                ...\n",
       "7305          فلك-علوم بحتة  موقع الكون - المجموعة الشمسية - أقمار زحل عودة...\n",
       "7306          فلك-علوم بحتة  موقع الكون - المجموعة الشمسية - أقمار زحل عودة...\n",
       "7307          فلك-علوم بحتة  موقع الكون - المجموعة الشمسية - أقمار زحل عودة...\n",
       "7308          فلك-علوم بحتة  موقع الكون - المجموعة الشمسية - حلقات زحل عودة...\n",
       "7309          فلك-علوم بحتة  موقع الكون - المجموعة الشمسية - حلقات زحل عودة...\n",
       "\n",
       "[7310 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtaining the title from the\n",
    "raw_data = pd.read_csv(\"data.csv\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>text_x</th>\n",
       "      <th>entities</th>\n",
       "      <th>title</th>\n",
       "      <th>text_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request-0</td>\n",
       "      <td>يتناول المهرجان هذا العام العلاقة بين الشعر وا...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "      <td>يتناول المهرجان هذا العام العلاقة بين الشعر وا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request-1</td>\n",
       "      <td>لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "      <td>لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   custom_id                                             text_x  \\\n",
       "0  request-0  يتناول المهرجان هذا العام العلاقة بين الشعر وا...   \n",
       "1  request-1  لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...   \n",
       "\n",
       "                                            entities                  title  \\\n",
       "0  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  الأدب العربي-أدبيات   \n",
       "1  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  الأدب العربي-أدبيات   \n",
       "\n",
       "                                              text_y  \n",
       "0  يتناول المهرجان هذا العام العلاقة بين الشعر وا...  \n",
       "1  لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging the title in \n",
    "df = pd.merge(df, raw_data, left_index=True, right_index=True)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request-0</td>\n",
       "      <td>يتناول المهرجان هذا العام العلاقة بين الشعر وا...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request-1</td>\n",
       "      <td>لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   custom_id                                               text  \\\n",
       "0  request-0  يتناول المهرجان هذا العام العلاقة بين الشعر وا...   \n",
       "1  request-1  لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...   \n",
       "\n",
       "                                            entities                  title  \n",
       "0  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  الأدب العربي-أدبيات  \n",
       "1  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  الأدب العربي-أدبيات  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[\"text_y\"], inplace=True)\n",
    "df.rename(columns={\"text_x\":\"text\"}, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the final combined Dataset\n",
    "df.to_csv(\"labelled_data.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>request-2659</td>\n",
       "      <td>موقع القانون الليبي - Law Of Libya - المقالات ...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "      <td>القانون-علوم اجتماعية</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>request-3053</td>\n",
       "      <td>موقع القانون الليبي - Law Of Libya - المرأة ال...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "      <td>القانون-علوم اجتماعية</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>request-2474</td>\n",
       "      <td>صدر عن الشيخ محمد بن مبارك آل خليفة نائب رئيس ...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...</td>\n",
       "      <td>القانون-علوم اجتماعية</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         custom_id                                               text  \\\n",
       "2659  request-2659  موقع القانون الليبي - Law Of Libya - المقالات ...   \n",
       "3053  request-3053  موقع القانون الليبي - Law Of Libya - المرأة ال...   \n",
       "2474  request-2474  صدر عن الشيخ محمد بن مبارك آل خليفة نائب رئيس ...   \n",
       "\n",
       "                                               entities                  title  \n",
       "2659  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  القانون-علوم اجتماعية  \n",
       "3053  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  القانون-علوم اجتماعية  \n",
       "2474  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...  القانون-علوم اجتماعية  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib.parse\n",
    "df = pd.read_csv(\"labelled_data.csv\", encoding='utf-8-sig')\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the text into BIO tagging\n",
    "def apply_bio_tagging(row):\n",
    "    try: \n",
    "        text = row.text\n",
    "        # entities = urllib.parse.unquote(row[\"entities\"].strip(\"```\").replace(\"json\", \"\",1))\n",
    "        entities = json.loads(row[\"entities\"].strip(\"```\").replace(\"json\", \"\",1))[\"entities\"]\n",
    "        # entities = json.loads(row['entities']).strip(\"```\")['entities']\n",
    "        \n",
    "        # tokenizing the text into words and making them all tagged as O\n",
    "        text_tokens = text.split()  \n",
    "        bio_tags = ['O'] * len(text_tokens)  \n",
    "        \n",
    "        # Iterate over the entities and mark BIO tags\n",
    "        for entity in entities:\n",
    "            entity_text = entity['text']\n",
    "            entity_category = entity['category']\n",
    "\n",
    "            # Find the tokens that belong to the entity\n",
    "            entity_tokens = entity_text.split() \n",
    "            \n",
    "            # BO tagging the first token of the entity as 'B-{category}' and others as 'I-{category}'\n",
    "            \n",
    "            for idx, entity_token in enumerate(entity_tokens):\n",
    "                try:\n",
    "                    if idx == 0:\n",
    "                        bio_tags[text_tokens.index(entity_token)] = f'B-{entity_category}'\n",
    "                    else:\n",
    "                        bio_tags[text_tokens.index(entity_token)] = f'I-{entity_category}'\n",
    "                except:\n",
    "                    # get the index of the text token that contains the entity-token and then mark it\n",
    "                    matching_index = next((index for index, item in enumerate(text_tokens) if entity_token in item), None)\n",
    "                    if matching_index is not None:\n",
    "                        if idx == 0:\n",
    "                            bio_tags[matching_index] = f'B-{entity_category}'\n",
    "                        else:\n",
    "                            bio_tags[matching_index] = f'I-{entity_category}'   \n",
    "\n",
    "    except:\n",
    "        print(row)\n",
    "        pass\n",
    "    return bio_tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_id                                          request-880\n",
      "text         CNNArabic.com - السعودية تقود موجة مكاسب بالأس...\n",
      "entities     ```json\\n{\\n  \"entities\": [\\n    {\\n      \"tex...\n",
      "title                                 الإقتصاد-علوم إجتماعية\n",
      "Name: 880, dtype: object\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'bio_tags' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply the function to the dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbio_tags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapply_bio_tagging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Display the resulta\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\moham\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\moham\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moham\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\moham\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m, in \u001b[0;36mapply_bio_tagging\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(row)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbio_tags\u001b[49m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'bio_tags' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Apply the function to the dataframe\n",
    "df['bio_tags'] = df.apply(apply_bio_tagging, axis=1)\n",
    "\n",
    "# Display the resulta\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_bio_tagging(df.iloc[880])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"entities\": [\\n    {\\n      \"text\": \"د. محمود السمرة\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 224,\\n      \"end_position\": 241\\n    },\\n    {\\n      \"text\": \"د. أمل نصير\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 292,\\n      \"end_position\": 304\\n    },\\n    {\\n      \"text\": \"طه حسين\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 363,\\n      \"end_position\": 371\\n    },\\n    {\\n      \"text\": \"الأربعاء\",\\n      \"category\": \"ORDINAL\",\\n      \"start_position\": 373,\\n      \"end_position\": 380\\n    },\\n    {\\n      \"text\": \"صحيفة الغد\",\\n      \"category\": \"ORG\",\\n      \"start_position\": 524,\\n      \"end_position\": 537\\n    },\\n    {\\n      \"text\": \"العالم\",\\n      \"category\": \"LOC\",\\n      \"start_position\": 22,\\n      \"end_position\": 27\\n    },\\n    {\\n      \"text\": \"العقاد\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 812,\\n      \"end_position\": 818\\n    },\\n    {\\n      \"text\": \"الكافوريات\",\\n      \"category\": \"CARDINAL\",\\n      \"start_position\": 815,\\n      \"end_position\": 828\\n    },\\n    {\\n      \"text\": \"الزمن\",\\n      \"category\": \"CARDINAL\",\\n      \"start_position\": 996,\\n      \"end_position\": 1001\\n    }\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.entities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"text\": \"د. محمود السمرة\",\n",
      "      \"category\": \"PERSON\",\n",
      "      \"start_position\": 224,\n",
      "      \"end_position\": 241\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"د. أمل نصير\",\n",
      "      \"category\": \"PERSON\",\n",
      "      \"start_position\": 292,\n",
      "      \"end_position\": 304\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"طه حسين\",\n",
      "      \"category\": \"PERSON\",\n",
      "      \"start_position\": 363,\n",
      "      \"end_position\": 371\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"الأربعاء\",\n",
      "      \"category\": \"ORDINAL\",\n",
      "      \"start_position\": 373,\n",
      "      \"end_position\": 380\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"صحيفة الغد\",\n",
      "      \"category\": \"ORG\",\n",
      "      \"start_position\": 524,\n",
      "      \"end_position\": 537\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"العالم\",\n",
      "      \"category\": \"LOC\",\n",
      "      \"start_position\": 22,\n",
      "      \"end_position\": 27\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"العقاد\",\n",
      "      \"category\": \"PERSON\",\n",
      "      \"start_position\": 812,\n",
      "      \"end_position\": 818\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"الكافوريات\",\n",
      "      \"category\": \"CARDINAL\",\n",
      "      \"start_position\": 815,\n",
      "      \"end_position\": 828\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"الزمن\",\n",
      "      \"category\": \"CARDINAL\",\n",
      "      \"start_position\": 996,\n",
      "      \"end_position\": 1001\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "\n",
    "# The input string (URL-encoded JSON)\n",
    "json_str = '''```json\\n{\\n  \"entities\": [\\n    {\\n      \"text\": \"د. محمود السمرة\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 224,\\n      \"end_position\": 241\\n    },\\n    {\\n      \"text\": \"د. أمل نصير\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 292,\\n      \"end_position\": 304\\n    },\\n    {\\n      \"text\": \"طه حسين\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 363,\\n      \"end_position\": 371\\n    },\\n    {\\n      \"text\": \"الأربعاء\",\\n      \"category\": \"ORDINAL\",\\n      \"start_position\": 373,\\n      \"end_position\": 380\\n    },\\n    {\\n      \"text\": \"صحيفة الغد\",\\n      \"category\": \"ORG\",\\n      \"start_position\": 524,\\n      \"end_position\": 537\\n    },\\n    {\\n      \"text\": \"العالم\",\\n      \"category\": \"LOC\",\\n      \"start_position\": 22,\\n      \"end_position\": 27\\n    },\\n    {\\n      \"text\": \"العقاد\",\\n      \"category\": \"PERSON\",\\n      \"start_position\": 812,\\n      \"end_position\": 818\\n    },\\n    {\\n      \"text\": \"الكافوريات\",\\n      \"category\": \"CARDINAL\",\\n      \"start_position\": 815,\\n      \"end_position\": 828\\n    },\\n    {\\n      \"text\": \"الزمن\",\\n      \"category\": \"CARDINAL\",\\n      \"start_position\": 996,\\n      \"end_position\": 1001\\n    }\\n  ]\\n}\\n```'''\n",
    "\n",
    "# Decode the URL-encoded text\n",
    "decoded_str = urllib.parse.unquote(json_str.strip(\"```\").replace(\"json\", \"\",1))\n",
    "\n",
    "# Parse the decoded string into a Python dictionary (JSON)\n",
    "data = json.loads(json_str.strip(\"```\").replace(\"json\", \"\",1))\n",
    "\n",
    "# Print the JSON object (with non-ASCII characters properly displayed)\n",
    "print(json.dumps(data, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7310, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "      <td>يتناول المهرجان هذا العام العلاقة بين الشعر وا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الأدب العربي-أدبيات</td>\n",
       "      <td>لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                               text\n",
       "0  الأدب العربي-أدبيات  يتناول المهرجان هذا العام العلاقة بين الشعر وا...\n",
       "1  الأدب العربي-أدبيات  لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['الأدب العربي-أدبيات', 'الإقتصاد-علوم إجتماعية',\n",
       "       'السياسة-علوم اجتماعية', 'القانون-علوم اجتماعية', 'رياضة',\n",
       "       'عام- فنون', 'عام-إسلام-ديانات', 'علم الكمبيوتر-علوم بحتة',\n",
       "       'علوم صحية-علوم تطبيقية', 'فلك-علوم بحتة'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"title\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_val = df[\"text\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['يتناول المهرجان هذا العام العلاقة بين الشعر والجنون والحزن. ويتضمن أمسيات شعرية مع عروض إخراجية للقصائد بمصاحبة الموسيقى والترجمات للهولندية والإنكليزية، إضافة إلى عروض سينمائية وموسيقية، ومحاضرات وجلسات حوارية تتناول هذه الموضوعة. ويسلط مهرجان هذا العام الضوء لأول مرة على الشعر في منطقة القوقاز. تبدأ الفعاليات السبت 16 حزيران / مايو بقصيدة \"الكلمة الواحدة\" وهي عبارة عن ملحمة غنائية طويلة يطلقها جميع الشعراء المشاركين في موكب ضخم، حيث يقرأ كل شاعر قصيدة تتكون من كلمة واحدة فقط تمثل مُلهما رئيسيًّا له، أو كلمة يراها ضائعة من الزمن والقاموس، أو كلمة تعد مفتاحا أو رمزا لشيء محبب بالنسبة له. تيمة المهرجان هي العلاقة ما بين الشعر والجنون، أو الخيط الرهيف الفاصل بين الإبداع وبين الاختلال العقلي والجنون، والدور الذي يلعبه الحزن في تعزيز كلٍّ منهما. يقول د. محمود السمرة في تقديمه لكتاب د. أمل نصير \" حول نار الشعر القديم: مقاربات نقدية \" الصادر حديثا \" هذه الدراسة قيمة، تقدمها لنا الدكتورة امل نصير، فإذا بالشعر العصي على الفهم، شعر جميل واضح، تقف عنده معجبا بما تقرأ وتسأل نفسك: كيف فاتك الوقوع عليه .ويجعلك تنشط باحثا عن شعر آخر جميل غائب في المصادر\"، ويضيف السمرة إن \" تقريب هذا الشعر الجميل من نفوس ابناء زماننا كما فعل طه حسين في \"حديث الاربعاء\"، لهو عمل علمي تشكر عليه المؤلفة\". وتقول د أمل نصير في كتابها – وفق ما ذكرت صحيفة \"الغد\" الأردنية - \" ان الفكر النقدي هو مظهر من مظاهر نشاط العقل الانساني المهمة حيث يسعى الانسان جاهدا الى فهم التجربة الانسانية ما وسعه ذلك مستفيدا من كل ما يملك من ادوات المعرفة والفهم، ولعل الاطلاع على النظريات النقدية الحديثة ومناهج النقد الغربية هي واحدة من هذه الادوات المهمة في هذا المجال خاصة في درس النص الادبي\". وتضيف نصير \"من هذا المنطلق عمدت الى الشعر العربي القديم واخترت في الفصل الاول المتنبي الذي اتحفنا بشعر لا تمل قرءاته ابدا حيث يخرج الناظر فيه بجديد كلما اعاد قراءاته، واخترت من شعره الكافوريات اي ما قاله في كافور الاخشيدي من شعر مدح او هجاء موضحة ما في هذا الشعر من مفارقة، فكان بعنوان \"المفارقة في كافوريات المتنبي\" وقد قسمت هذا الشعر الى قسمين: الاول \"الكافوريات المدحية\" وهذه كانت مشمولة بالمفارقة، لانه قصدغير ما اظهر، فقد خرج كثير من شعره هذا عن الممكن الى المستحيل في مدحه لكافور بما يحتمل المفارقة\". وتخصص نصير الفصل الثاني \"لمكان ذي الرمة\" حيث قامت بدراسة فاعليته في بناء القصيدة عند مركزه على مقدمة القصيدة. وتركز على استطاعة ذي الرمة \"تصور حياة الانسان العربي داخل الصحراء ووصف معاناته من خلال حديثه عن الطلل ورحلة الظعائن حيث المكان الخصيب، وكذلك الرحلة داخل الصحراء، فالطلل يؤدي الى المكان الخصيب وكذلك الرحلة داخل الصحراء تؤدي الى انتصار الارادة وجلب الحياة والخصب موضع الرجاء\".أما الفصل الثالث فجعلته  لدراسة \"الزمن عند الشعراء العذريين في العصر الاموي\" وقد \"بدأت اولا بتوضيح معنى الزمن، وعرضت لمفاهيمه المختلفة عند الفلاسفة القدماء والمحدثين، ثم عرضت للأسباب التي دعتني الى دراسته عند الشعراء العذريين في العصر الاموي بشكل خاص، حيث تكشفت عن رؤية العذريين للزمن من خلال ملاحظتي للدهر، والموت، والشيب، والطلل، وثلاثية الزمن\".',\n",
       "       'لاشكّ فى أنّنى لا أرمى من وراء هذا العنوان إلى أى توصيف فيزيائى، إنّما هى قراءة لحالة قائمة فى واقع الثقافة العربيّة عموماً، فمثقّف العين الواحدة هو الذى يحاول أن يحجب عن الآخرين سمة الثقافة، ويسحب منهم حياز الامتياز، أمّا لماذا، فلأنّهم يسقطون فى الامتحان الثقافىّ.الغريب أنّ قراءات هؤلاء المجموعة من المثقّفين تتشابه، وكأنّهم يشكّلون مجموعة، لقد قرأوا بعض الروايات المترجمة، وبعض كتب المذكّرات، وشعر درويش ونزار، وأدونيس، كما قرأوا كتب \"التابو\" التراثى فى طبعة رياض الريّس، لكنّ أحداً لم يرشدهم بعد إلى درب \"ابن أبى إسحق الرقيق النديم\"، أو إلى تنظيرات \"المعرّى\" الأنثروبولوجيّة فى مقدّمة رسالته \"الصاهل والشاحج\".ولابدّ لهم فى الفلسفة من القليل من نيتشه، وماركس، وربّما شبينغلر. وفى النقد يذهبون إلى حوارية باختين الروائية، بوصفهم يسيرون يساراً، إذ يفتح لهم أفق دمقرطة، ويرفدونه بشىء من تفكيكيّة \"ديريدا\"، لأنّ البنى باتت بحاجة ملحّة إلى تفكيك، ليتمّ تركيبها من جديد، أو على حدّ قول المثل الشعبى، \"إذا ما خربت، ما بتعمر!\" وفى الدين هم متمحّصون فى قضيّة التعدّد، وشروط الزنا. وقد بدأوا يتفقّهون فى التصوّف باعتباره مزاج المرحلة، إذ بدأوا يفتحون آفاقاً جديدة لعلاقات جلال الدين الرومى بـ \"شمس تبريز\"، بل مولانا جلال الدين كما يحلو لهم أن يترنّموا بالاسم، من غير أن يخطر فى بالهم أنّ هذا الاتجاه فى الأدب قد مرّ عليه كثيرون، ليس آخرهم \"البرعى\" و\"الباعونيّةط.أمّا تاريخ العرب والأقوام الأخرى فقد أُسقط من منهاج الثقافة، ومثله الفلسفة اليونانيّة والإسلاميّة، وكذلك كتب اللغة، فهى صعبة للغاية، وبالنسبة للمعلّقات وشعر عرب قديم الزمان فانسَ أمره، فأصحابنا لا يفرّقون بين وحش وجرة، وبين الجآذر الذين هم فى زى الأعاريب، يأتى الواحد منهم، ويسرد أمامك عبارة من رواية لماركيز، أو لتابوكي، أو إيكو، أو كويلّو، وبالطبع لم يصلوا إلى عبارات خالد حسينى، لأنّه لم يترجم إلى العربيّة بعد! وحينما تقول له إنّك لا تعرف أو لا تتذكّر من هو صاحب العبارة، يفغر فاه، ويقول: معقول، لا تحفظ مثل هذا الغناء السماوى! وينتابهم حرج إذا ما اضطروا للبوح بأنّهم قرأوا لفلان أو فلان من أبناء جلدتهم!ليست الثقافة حبّة دواء، أو مشروباً للطاقة، تتناوله فتنبت لك أجنحة وتصبح مثقّفاً! وليست الثقافة قراءة خمسين كتاباً، وحفظ عبارات شعريّة فى الروايات، أو كلام مأثور من هنا وهناك، الثقافة طريقة حياة، تبدأ بطريقة شرب الماء، ولا تنتهى بكتابة الرواية. نحن نقرأ، لنكوّن رؤياتنا عن ظواهر الواقع والطبيعة، وما وراءهما، نقرأ لنصوغ عباراتنا، لا لنحفظ عبارات الآخرين، بل نقرأ لننسى، لا لنتذكّر، وقد أدرك العربى هذه القضيّة قبل أن ندركها بقرون، وقصّة الرجل الذى ذهب إلى \"ابن الأعرابىّ\" معروفة، إذ طلب منه إرشاده إلى درب الشعر، فقال له: اذهب واحفظ مائة ألف بيت، ولمّا عاد بعد عام، قال له: اذهب فانسها!ماذا قرأت؟ سؤال محيّر، إذ كيف أحكى لسائلى خمساً وعشرين سنة من حياتى بل أكثر فى خمس دقائق.',\n",
       "       'لفت الدكتور خالد جودة إلى الإتجاهات المستحدثة في كتابة الأدب كأدب المدونات وأدب البنات وغيره في ظل وسائط حديثة وتأثيرات مجتمعية متغيرة .جاء ذلك ضمن جلسة بعنوان \"الظواهر الأدبية الجديدة\" عقدت بقصر ثقافة الجيزة أمس في إطار مؤتمر أدباء مصر.وأضاف جودة أن مفهوم \"الاتجاه\"، ظهر في دراسات متعددة نفسية وفكرية وتربوية بمعانيها المتعددة وهو مفهوم كثير التداول في الحياة العامة والخاصة، إذ يعطى معنى اعتبارياً عندما يرتبط بالرأي الذي يكونه الفرد نحو موضوع معين ويصيغ سلوكه في مواقف الحياة المختلفة.وبالنسبة للمجال الأدبي يرى البعض \"أن دراسة الاتجاهات الأدبية هو معرفة وجهة وسير المواضيع الأدبية الثقافية والفكرية والفنية المختلفة\" والتي نشرت في وسيط معين لتوصيل رسالة ما إلى القارئ وما يرتبط بدراسة هذه الموضوعات من مؤثرات وشواهد دالة .ويرتبط بمفهوم \"الاتجاه\" أيضاً مفهوم \"الظاهرة\" التي تعنى واقعة متكررة بنفس الأسلوب وبنفس الشكل بحيث تمثل أمراً لافتاً للنظر، ومستحقاً للتأمل والدرس، فالظاهرة إما أن تكون إيجابية أو سلبية، والظاهرة الثقافية والأدبية عامة هي التي تحفر في الواقع الثقافي مجراها لتؤسس بالتدريج إتجاهاً عاماً يمكن تحديد ملامحه والوقوف على أهم خصائصه.وتناولت د. رشا صالح في بحثها علاقة الأدب بالوسائط الإعلامية، والتي أكدت أنها قوية تتجلى في مظاهرها في ظهور أجناس أدبية جديدة وطرق للتعبير ، مستعرضة رواية \"فى كل أسبوع يوم جمعة\" لإبراهيم عبدالمجيد.وتناولت فى البحث خصائص متن الرواية ومبناها الحكائى من خلال تقاليد الشكلانيين الروس، وإضافات جيرار جينت، وعلاقتها بتأثير الميديا فيها، وأشارت الى أن \"المتن الحكائى\" أى القص هو مجموع الأحداث التى تتصل فيما بينها، والتى تعرض وفق نظام طبيعى، أى النظام الوقتى والسببى للأحداث من خلال مادة أولية للحكاية لا تنفصل عن إحداثياتها الزمانية والمكانية، ولا عن الشخصيات، أما المبنى الحكائى اى الخطاب، أو السرد، أو التقديم الخطابى، هو طريقة البناء التى تتم بمقتضاها إدراج تلك الأحداث فى العمل الفنى.وتناول مجاهد العزب في بحثه الشعر والميديا باعتبارها من الظواهر الأدبية الجديدة، وجاء فيها أن الفيس بوك مثَّل ويُمثل أداة اتاحت للمبدعين من الشعراء نشر إبداعهم مباشرة دون المرور بدورة النشر الورقى المعتادة أو التى تتم عبر وسائل الإعلام التى يقف فيها بعض الوسطاء بين المبدع وجمهوره.مؤكدا إن هذه الأداة أتاحت للمبدع أن يكون صاحب القرار الوحيد فى أن ينشر ماشاء وقتما شاء للدرجة التى أصبح معها كأنه يمتلك صحيفة ينشر فيها ما يحب بحرية شبه مطلقة.',\n",
       "       ...,\n",
       "       'موقع الكون - المجموعة الشمسية - أقمار زحل عودة للصفحة الرئيسية - سجل الزوار المجموعة الشمسية - الكواكب وتوابعها - أقمار زحل - فيـبي عودة إلى زحل إقمار زحـل تيتان فيـبـي رييا ديون باندورة مايماس إيباتوس تيثيس إنثيلادوس أقمار اخرى متوسط المسافة من زحل 12,952,000 كيلومتر قطر القمر 220 كيلومتر أكتشفه ويليام هنري بيكرينج William Henry Pickering عام 1898، وهو أبعد أقمار زحل المعروفة. كل أقمار زحل ماعدا إيباتوس Iapetus وفيبي يدوران حول مستوى خط إستواء زحل تقريبا. على العكس من باقي أقمار زحل فإن مدار فيبي ينحرف تقريبا بمقدار 175° (قطبه الشمالي في الإتجاه المعاكس لزحل). هناك دليل محتمل بأن فيبي جسم غني بالثلج تحت طبقة رقيقة من مواد مظلمة. الحفرة المعروفة تعرض طبقتان أو أكثر من المواد بين الامعة و المظلمة. يعتقد علماء كاسيني بأن هذه الطبقات قد تكونت أثناء تشكيل الحفرة، عندما القيت المقذوفات من الحفرة واخفت السطح السابق بطبقة رقيقة نسبيا من مادة مظلمة. مدار فيبي الغريب العكسي والمعان الغير عادي قد يشيران بأن هذا القمر قد يكون مذنبا أو جسم من حزام كيوبر Kuiper وأسر بجاذبية زحل. بيانات كاسيني Cassini تعزز هذه الفكرة بكشف ثاني أكسيد الكربون المحصور في صخورها. وهذه تلغي الفكرة السابقة التي كانت تقول بأنه كويكبا تم أسره. التحليل الكيميائي له يشبه إلى حد كبير بلوتو وتريتون، ومن المحتمل جدا بأن يكون مشابه للتركيب الكيميائي للنظام الشمسي الخارجي خلال العصور الاولى. alnomrosi.net 2005-2006 حقوق النشر متاحة للجميع بشرط ذكر المصدر',\n",
       "       'موقع الكون - المجموعة الشمسية - أقمار زحل عودة للصفحة الرئيسية - سجل الزوار المجموعة الشمسية - الكواكب وتوابعها - أقمار زحل - رييـا عودة إلى زحل إقمار زحـل تيتان فيبي رييـا ديون باندورة مايماس إيباتوس تيثيس إنثيلادوس أقمار اخرى متوسط المسافة من زحل 527,040 كيلومتر قطر القمر 1530 كيلومتر ثاني أكبر أقمار زحل والرابع عشر في حيث الترتيب بعدا عنه، إكتشفه كاسيني في عام 1672. من الاقمار الثلجية ويتشابه مع أقمار زحل مثل تيثيس و ديون ، مؤلف من قلب من الصخور تمثل ثلث كتلة القمر أما ثلثه الباقي فهو من الثلج المائي. تاريخه يماثل تاريخ ديون ، فنجد أن معظم الحفر العملاقة تقع في الجزء الذي لا يواجه كوكبه، أما الاقل ففي الجهة التي تقابل زحل. وتقول النظريات أن القمر كان يواجه كوكبه من الجهة العكسية في فترة القصف العظيم، تعرض خلالها للقصف بواسطة نيازك عملاقة تسببت في تغيير الجهة التي تواجه الكوكب إلى الجهة العكسية، حيث أن النظريات تقول أن حفر عملاقة في حدود قطر يبلغ ثلاثون كيلومتر من شأنها أن تسرع من دوران القمر، وحيث أنه تعرض لاكثر من ذلك فقد يكون هذا الاعتقاد مناسب لهذه الحالة. كما ديون فإن المادة اللامعه على سطح القمر ما تزال غامضة. لكن على ما يبدو هي طبقة من مادة تعكس الضوء بدرجة عالية ورقيقة جدا بما فيه الكفاية حتى إنها لا تحجب المميزات السطحية، وقد يكون مصدرها من الإنفجارات على طول الشقوقِ في سطحِ القمر والتي تراجعت إلى السطح على شكل ثلج أَو رماد. alnomrosi.net 2005-2006 حقوق النشر متاحة للجميع بشرط ذكر المصدر',\n",
       "       'موقع الكون - المجموعة الشمسية - حلقات زحل عودة للصفحة الرئيسية - سجل الزوار المجموعة الشمسية - الكواكب وتوابعها - حلقات زحل عودة إلى زحل إضغط على الصورة للتكبير حلقات زحل مع بعض أقماره v حلقات زحل المميزة لهذا الكوكب الجميل بعضها رقيق جدا، مع أن قطرها حوالي 250,000 كيلومتر أو أكثر فهي أقل في السمك من الكيلومتر الواحد في بعض الحلقات وتبلغ سمك بعضها الاخر حوالي 10 كيلومتر ، على الرغم من شكلها الرائع، فإن هناك القليل جدا من المواد فيها، وإذا ضغطت هذه الحلقات في جسم واحد سوف تكون جسم لا يتعدى حجمه أكثر من 100 كيلومتر، ذرات الحلقة هي من الثلج المائي، أو ربما تتكون من ذرات صخرية يغلفها الثلج. أوضحت الصور الملتقطة لحلقات زحلِ انها مكونة من مئات آلالاف من الحلقات، وكذلك مناطقِ الفجوات بين الحلقات تحتوي أيضا على حلقات أضعف. كما ةتشير الدلائل على أن تلك الحلقات هي من جزيئات التي في الغالب من بلورات الثلجِ، وبأحجام قد تكون كبيرة بالأمتار أو صغيرة بالسنتيمترات، أما الكتلة الكلية للحلقات فهي تقدر بكتلة قمر متوسط الحجم. نشؤء الحلقة أصل حلقات زحل مجهولة، مع أنه من الممكن أنها تكونت مع تكون الكوكب نفسه، او ربما انها كانت قمرا ثم أنفجر وتفتت بفعل جاذبية زحل وجذب ذلك الكوكب بقايا الانفجار لتدور في فلكه ، وهناك رأي أخر يقول ان الحلقات ما هي إلا مواد من أقمار زحل نفسه جذبها الكوكب، وأنظمة الحلقة غير مستقرة وهي تتجدد بإستمرار بتأثير العمليات المستمرة، اما المجموعة الحالية للحلقات يحتمل أن تكون بعمر فقط بضعة مئات الملايين من السنين. كان من المتوقع أن الإصطدامات التي تحدث بين جزيئات او مكونات الحلقة هي التي تؤثر على شكل الحلقة. لكن الرحلات الفضائية اوضحت عاملا أخر يؤثر على شكل وترتيب الحلقات وهو عامل التنافر في الشحنات الكهربائية التي تشحن الجزيئات إلى جانب عامل القوة الجذبية . كما اوضحت الاكتشافات التي تمت من خلال رحلة فواجير أن الحلقات ليس من الضروري ان تكون دائرية، كما اكتشف أن الحلقة الخارجيةَ لحلقة ظلت في مكانها بالتفاعل التجاذبي من قمرين صغيرين يقع احدهما داخل الحلقة والاخر خارجها. ترتيب الحلقات تتكون حلقات كوكب زحلِ من خمس حلقات رئيسيةِ هي: G و F و A و B و C مرتبة من الخارج إلى الداخل (في الواقع هذه التقسيماتِ الرئيسيةِ مقسمة إلى آلافِ الحلقات الفرديةِ). الحلقات F و G حلقات رقيقة وصعبة الرؤية، بينما الحلقات الاخرى A و B و C حلقات واسعة وسهلة الرؤية. الفجوة الكبيرة بين الحلقة A و B تسمى قسم كاسيني. الإسم المسافة (كيلومتر) العرض (كم) السمك (كم) البداية النهاية D 66,000 73,150 7,150 C 74,500 92,000 17,500 فاصل ماكسويل ( Maxwell ) 87,500 88,000 500 B 92,000 117,500 25,500 0.1 - 1 قسم كاسيني (Cassini Div) 117,500 122,200 4,700 فاصل فاصل هويجنز ( Huygens ) 117,680 285-440 فاصل فرعي A 122,200 136,800 14,600 0.1 - 1 فاصل إنكي ( Encke ) 133,410 133,740 330 فاصل كيلر ( Keeler ) 136,510 136,550 40 F 140,210 30-500 G 165,800 173,800 8,000 100-1,000 E 180,000 480,000 300,000 1,000 وقد رصد العلماء انفجارا لأوكسجين ذري حول الكوكب، ويدلل ذلك على ان حلقات الكوكب من الممكن أن تتآكل وعلى ذلك يمكن لهذه الحلقات ان تندثر في غضون مئة مليون عام. ويفسر العلماء ان هذا الاوكسجين الذري يشير على وقوع تصادم بين الجسيمات في احدى حلقات الكوكب والتي تتألف من الثلج في معظمها ومن الممكن ان الغاز قد انبعث منها أثناء انشطارها نتيجة التصادم. الحلقة E والتي هي أبعد حلقات زحل وهي حلقة عريضة جدا لكنها ذات إضاءة خافتة تتكون من مواد دقيقة الحجم من الثلج والتراب، تبدأ من مدار القمر ميماس Mimas وتنتهي تقريبا حول مدار القمر ريا Rhea. alnomrosi.net 2005-2006 حقوق النشر متاحة للجميع بشرط ذكر المصدر'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa1 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mparsers.pyx:1120\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1272\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1285\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1535\u001b[0m, in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa1 in position 0: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m labelled_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabelled_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moham\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moham\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moham\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\moham\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:921\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1066\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1127\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1272\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1285\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:1535\u001b[0m, in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa1 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "labelled_data = pd.read_csv(\"labelled_data.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content\":\"Identify and label named entities in the given text block using a predefined list of named entity recognition (NER) categories. Ensure the response is structured in a JSON format.\n",
      "\n",
      "# Steps\n",
      "\n",
      "1. **Input Analysis**: Review the provided text block.\n",
      "2. **Entity Recognition**: Identify named entities in the text based on the predefined NER list.\n",
      "3. **Entity Labeling**: Assign the appropriate NER category to each identified entity.\n",
      "4. **Structure Output**: Organize the labeled entities into the specified JSON format.\n",
      "\n",
      "# Output Format\n",
      "\n",
      "The output should be in the following JSON format:\n",
      "```json\n",
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"text\": \"[entity_text]\",\n",
      "      \"category\": \"[ner_category]\",\n",
      "      \"start_position\": [start_index],\n",
      "      \"end_position\": [end_index]\n",
      "    },\n",
      "    ...\n",
      "  ]\n",
      "}\n",
      "```\n",
      "# NER List\n",
      "\n",
      "PERSON: أسماء الأفراد (على سبيل المثال، \"أحمد محمد\").\n",
      "GPE (Geo-Political Entity): أسماء الدول، المدن، أو الولايات (على سبيل المثال، \"مصر\"، \"الرياض\").\n",
      "ORG: أسماء الشركات، الوكالات، أو المؤسسات (على سبيل المثال، \"الأمم المتحدة\"، \"شركة أرامكو\").\n",
      "LOC: المواقع غير الجغرافية السياسية، مثل الجبال أو الأنهار (على سبيل المثال، \"جبال الهيمالايا\"، \"نهر النيل\").\n",
      "DATE: التواريخ الموجودة في النص (على سبيل المثال، \"1 يناير 2025\")\n",
      "TIME: أوقات محددة (على سبيل المثال، \"الساعة 2:00 مساءً\").\n",
      "MONEY: القيم المالية (على سبيل المثال، \"$20\"، \"15 ريال\").\n",
      "PERCENT: النسب المئوية (على سبيل المثال، \"50%\").\n",
      "QUANTITY: الكميات القابلة للقياس (على سبيل المثال، \"5 كيلومترات\"، \"20 كيلوجرام\").\n",
      "ORDINAL: الترتيب أو التصنيف (على سبيل المثال، \"الأول\"، \"الثاني\").\n",
      "CARDINAL: الأرقام التي لا تندرج تحت فئات أخرى (على سبيل المثال، \"اثنان\"، \"100\")\n",
      "\n",
      "\n",
      "# Example\n",
      "\n",
      "**Input**: \n",
      "\"The CEO of OpenAI, Sam Altman, gave a talk in San Francisco on artificial intelligence.\"\n",
      "\n",
      "**Output**: \n",
      "```json\n",
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"text\": \"OpenAI\",\n",
      "      \"category\": \"ORG\",\n",
      "      \"start_position\": 11,\n",
      "      \"end_position\": 17\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Sam Altman\",\n",
      "      \"category\": \"PERSON\",\n",
      "      \"start_position\": 23,\n",
      "      \"end_position\": 33\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"San Francisco\",\n",
      "      \"category\": \"GPE\",\n",
      "      \"start_position\": 52,\n",
      "      \"end_position\": 65\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "# Notes\n",
      "\n",
      "- Ensure all entities are correctly identified and labeled according to the predefined NER list.\n",
      "- Consider edge cases where entities may overlap or have multiple possible classifications.\n",
      "- Be precise in determining the start and end positions of each entity within the text.\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "print (\"\"\"content\":\"Identify and label named entities in the given text block using a predefined list of named entity recognition (NER) categories. Ensure the response is structured in a JSON format.\\n\\n# Steps\\n\\n1. **Input Analysis**: Review the provided text block.\\n2. **Entity Recognition**: Identify named entities in the text based on the predefined NER list.\\n3. **Entity Labeling**: Assign the appropriate NER category to each identified entity.\\n4. **Structure Output**: Organize the labeled entities into the specified JSON format.\\n\\n# Output Format\\n\\nThe output should be in the following JSON format:\\n```json\\n{\\n  \\\"entities\\\": [\\n    {\\n      \\\"text\\\": \\\"[entity_text]\\\",\\n      \\\"category\\\": \\\"[ner_category]\\\",\\n      \\\"start_position\\\": [start_index],\\n      \\\"end_position\\\": [end_index]\\n    },\\n    ...\\n  ]\\n}\\n```\\n# NER List\\n\\nPERSON: أسماء الأفراد (على سبيل المثال، \\\"أحمد محمد\\\").\\nGPE (Geo-Political Entity): أسماء الدول، المدن، أو الولايات (على سبيل المثال، \\\"مصر\\\"، \\\"الرياض\\\").\\nORG: أسماء الشركات، الوكالات، أو المؤسسات (على سبيل المثال، \\\"الأمم المتحدة\\\"، \\\"شركة أرامكو\\\").\\nLOC: المواقع غير الجغرافية السياسية، مثل الجبال أو الأنهار (على سبيل المثال، \\\"جبال الهيمالايا\\\"، \\\"نهر النيل\\\").\\nDATE: التواريخ الموجودة في النص (على سبيل المثال، \\\"1 يناير 2025\\\")\\nTIME: أوقات محددة (على سبيل المثال، \\\"الساعة 2:00 مساءً\\\").\\nMONEY: القيم المالية (على سبيل المثال، \\\"$20\\\"، \\\"15 ريال\\\").\\nPERCENT: النسب المئوية (على سبيل المثال، \\\"50%\\\").\\nQUANTITY: الكميات القابلة للقياس (على سبيل المثال، \\\"5 كيلومترات\\\"، \\\"20 كيلوجرام\\\").\\nORDINAL: الترتيب أو التصنيف (على سبيل المثال، \\\"الأول\\\"، \\\"الثاني\\\").\\nCARDINAL: الأرقام التي لا تندرج تحت فئات أخرى (على سبيل المثال، \\\"اثنان\\\"، \\\"100\\\")\\n\\n\\n# Example\\n\\n**Input**: \\n\\\"The CEO of OpenAI, Sam Altman, gave a talk in San Francisco on artificial intelligence.\\\"\\n\\n**Output**: \\n```json\\n{\\n  \\\"entities\\\": [\\n    {\\n      \\\"text\\\": \\\"OpenAI\\\",\\n      \\\"category\\\": \\\"ORG\\\",\\n      \\\"start_position\\\": 11,\\n      \\\"end_position\\\": 17\\n    },\\n    {\\n      \\\"text\\\": \\\"Sam Altman\\\",\\n      \\\"category\\\": \\\"PERSON\\\",\\n      \\\"start_position\\\": 23,\\n      \\\"end_position\\\": 33\\n    },\\n    {\\n      \\\"text\\\": \\\"San Francisco\\\",\\n      \\\"category\\\": \\\"GPE\\\",\\n      \\\"start_position\\\": 52,\\n      \\\"end_position\\\": 65\\n    }\\n  ]\\n}\\n```\\n\\n# Notes\\n\\n- Ensure all entities are correctly identified and labeled according to the predefined NER list.\\n- Consider edge cases where entities may overlap or have multiple possible classifications.\\n- Be precise in determining the start and end positions of each entity within the text.\n",
    "       \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
